{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "As one of the largest social media websites in the world, Facebook is an attractive platform for businesses to reach their consumers. Almost all consumer-facing businesses have virtual presence on Facebook, in the form of Facebook business pages (e.g., see [here](https://www.facebook.com/target/) for Target's Facebook business page). Everyday, Facebook users who visit these business pages generate a large amount of posts. These user posts may represent customer complains, questions, or appreciations directed towards the focal businesses. \n",
    "\n",
    "For businesses, these user posts contain valuable information about customers' needs and preferences, and understanding what the user posts are talking about represents an important opportunity to get to know your customers in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Task\n",
    "\n",
    "For this assignment, you will use a **labeled dataset** named \"FB_posts_labeled.txt\". It is a **tab-delimited** file with the following fields:\n",
    "- postId: this is a unique identifier for each user post. There are 7961 posts in total;\n",
    "- message: this is the text of each post;\n",
    "- Appreciation: this is a binary (0/1) indicator of whether a post is an appreciation;\n",
    "- Complaint: this is a binary (0/1) indicator of whether a post is a customer complaint;\n",
    "- Feedback: this is a binary (0/1) indicator of whether a post is a customer feedback (e.g., questions and suggestions).\n",
    "\n",
    "Appreciation, Complaint, and Feedback are the three mutually exclusive content categories / classes in this dataset. They were labeled by humans, and the labeling isn't perfect (i.e., there may be ambiguous cases where the labels are not appropriate). However, for the sake of this assignment, let's treat them as the ground truth. **Your task is to build a text classifier to predict the content category of a post based on its textual content.** \n",
    "\n",
    "To evaluate the out-of-sample performance of your model, you will use it to make predictions for 2039 posts in an **unlabeled dataset** named \"FB_posts_unlabeled.txt\". It is also a tab-delimited file, but only has postId and message fields. I keep the ground truth labels for these posts in a private place, in order to objectively evaluate your model's performance. The performance metric I will use is **averaged F-measure** across the three categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your Predictions\n",
    "\n",
    "Throughout this assignment, you are encouraged to build different models and submit their predictions as many times as you'd like. To submit a set of predictions, you MUST adhere to the following format (a sample submission file that adheres to all the following requirements is provided on Canvas):\n",
    "\n",
    "1. The submission must be a csv file, with exactly four columns and 2040 rows;\n",
    "2. The first row must be the headers, specifically, \"postId,Appreciation_pred,Complaint_pred,Feedback_pred\". Spellings are case-sensitive;\n",
    "3. The first column must contain postId. The order of the posts doesn't matter - I will do a join between your predictions and the ground truth table based on postId;\n",
    "4. The remaining three columns contain your model's predictions for each post. Note that you must generate **binary predictions** for each category. In other words, the numbers in each of those three columns must be either 0 or 1. Also, a post can only belong to one category, so only 1 category can have value 1 and all the others must have value 0.\n",
    "\n",
    "Because I use an automated system to evaluate prediction performance, if your prediction file does not follow the above format, it won't be recognized. I suggest adapting the following pseudocode to generate the prediction file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/Users/haochunniu/Desktop/Python/Advance AI/HW1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Import train and test data\n",
    "raw=pd.read_table('FB_posts_labeled.txt')\n",
    "raw['label']=np.where(raw['Appreciation']==1,'Appreciation',np.where(raw['Complaint']==1,'Complaint','Feedback'))\n",
    "label=raw[['Appreciation','Complaint','Feedback']]\n",
    "test=pd.read_table('FB_posts_unlabeled.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=np.array(raw['message'])\n",
    "test_text=np.array(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-1.Text pre-processing for train data\n",
    "vectorize_layer = keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens = None,\n",
    "    standardize = 'lower_and_strip_punctuation',\n",
    "    split = 'whitespace',\n",
    "    ngrams = None,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-2. Apply it to the text data with \"adapt\"\n",
    "vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19465"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-1. Classification model of simple RNN\n",
    "model_rnn = keras.Sequential()\n",
    "\n",
    "model_rnn.add(vectorize_layer)\n",
    "\n",
    "model_rnn.add(keras.layers.Embedding(\n",
    "    input_dim = len(vectorize_layer.get_vocabulary()),\n",
    "    output_dim = 128,\n",
    "    mask_zero = True\n",
    "))\n",
    "\n",
    "model_rnn.add(keras.layers.SimpleRNN(128,return_sequences=True,dropout=0.2)) # see note below\n",
    "model_rnn.add(keras.layers.SimpleRNN(128,dropout=0.2))\n",
    "model_rnn.add(keras.layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3-2. Configure training / optimization\n",
    "model_rnn.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 30s 286ms/step - loss: 0.8959 - accuracy: 0.6170 - val_loss: 0.7875 - val_accuracy: 0.6566\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 0.4916 - accuracy: 0.8189 - val_loss: 0.5842 - val_accuracy: 0.7765\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.2101 - accuracy: 0.9290 - val_loss: 0.7170 - val_accuracy: 0.7577\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.1408 - accuracy: 0.9497 - val_loss: 0.7774 - val_accuracy: 0.7338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f81aab9bcd0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-3. Add early stopping layer\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=1)\n",
    "\n",
    "#3-4. Fit the model\n",
    "model_rnn.fit(x = train_text, y = label,\n",
    "              validation_split = 0.2,\n",
    "              epochs=10,\n",
    "              batch_size = 64,\n",
    "              callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Appreciation       0.93      0.93      0.93      2062\n",
      "   Complaint       0.96      0.94      0.95      4255\n",
      "    Feedback       0.89      0.93      0.91      1644\n",
      "\n",
      "    accuracy                           0.94      7961\n",
      "   macro avg       0.93      0.93      0.93      7961\n",
      "weighted avg       0.94      0.94      0.94      7961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3-5. Summary report of prediction on train data\n",
    "train_data_result=pd.DataFrame(model_rnn.predict(train_text), columns = ['Appreciation','Complaint','Feedback'])\n",
    "train_data_result['max']=train_data_result.max(axis = 1)\n",
    "train_data_result['label']=np.where(train_data_result['Appreciation']==train_data_result['max'],'Appreciation',np.where(train_data_result['Complaint']==train_data_result['max'],'Complaint','Feedback'))\n",
    "print(classification_report(raw['label'], train_data_result['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-1. Classification model of RNN with LSTM units\n",
    "model_lstm = keras.Sequential()\n",
    "\n",
    "model_lstm.add(vectorize_layer)\n",
    "\n",
    "model_lstm.add(keras.layers.Embedding(\n",
    "    input_dim = len(vectorize_layer.get_vocabulary()),\n",
    "    output_dim = 128,\n",
    "    mask_zero = True\n",
    "))\n",
    "\n",
    "model_lstm.add(keras.layers.LSTM(128,\n",
    "                                 dropout=0.2,\n",
    "                                 return_sequences=True))\n",
    "\n",
    "model_lstm.add(keras.layers.LSTM(128,\n",
    "                                 dropout=0.2,\n",
    "                                 return_sequences=True))\n",
    "\n",
    "model_lstm.add(keras.layers.LSTM(128,\n",
    "                                 dropout=0.2))\n",
    "\n",
    "model_lstm.add(keras.layers.Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4-2. Configure training / optimization\n",
    "\n",
    "#Create F1-Score metrics\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "#Compile the loss function for the model\n",
    "model_lstm.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                   optimizer='adam',\n",
    "                   metrics=[f1_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 145s 3s/step - loss: 1.1295 - f1_m: 0.3839 - val_loss: 0.7167 - val_f1_m: 0.7129\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 137s 3s/step - loss: 0.6213 - f1_m: 0.7873 - val_loss: 0.5458 - val_f1_m: 0.7620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3d9d55110>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4-3. Add early stopping layer\n",
    "early_stopping = EarlyStopping(monitor='val_f1_m',patience=1)\n",
    "\n",
    "#4-4. Fit the model & Mannualy set class weight\n",
    "weight = {0: 1.,\n",
    "          1: 1.,\n",
    "          2: 2}\n",
    "\n",
    "model_lstm.fit(x = train_text, y = label,\n",
    "               validation_split = 0.2,\n",
    "               epochs=10,\n",
    "               batch_size = 128,\n",
    "               callbacks=[early_stopping],\n",
    "               class_weight=weight\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Appreciation       0.91      0.88      0.89      2062\n",
      "   Complaint       0.92      0.87      0.90      4255\n",
      "    Feedback       0.74      0.88      0.81      1644\n",
      "\n",
      "    accuracy                           0.87      7961\n",
      "   macro avg       0.86      0.88      0.87      7961\n",
      "weighted avg       0.88      0.87      0.88      7961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4-5. Summary report of prediction on train data\n",
    "train_data_result=pd.DataFrame(model_lstm.predict(train_text), columns = ['Appreciation','Complaint','Feedback'])\n",
    "train_data_result['max']=train_data_result.max(axis = 1)\n",
    "train_data_result['label']=np.where(train_data_result['Appreciation']==train_data_result['max'],'Appreciation',np.where(train_data_result['Complaint']==train_data_result['max'],'Complaint','Feedback'))\n",
    "print(classification_report(raw['label'], train_data_result['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data\n",
    "test_data_result=pd.DataFrame(model_lstm.predict(test_text), columns = ['Appreciation','Complaint','Feedback'])\n",
    "test_data_result['max']=test_data_result.max(axis = 1)\n",
    "test_data_result['label']=np.where(test_data_result['Appreciation']==test_data_result['max'],'Appreciation',np.where(test_data_result['Complaint']==test_data_result['max'],'Complaint','Feedback'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label']=test_data_result['label']\n",
    "test=test.drop(columns=['message'])\n",
    "test=pd.get_dummies(test,\n",
    "                    columns=['label'])\n",
    "test.columns=['postId','Appreciation_pred','Complaint_pred','Feedback_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('Prediction_on_Test.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To use the submission system**:\n",
    "1. Visit [http://3.22.117.95:3838/FBapp](http://3.22.117.95:3838/FBapp) to access the prediction submission system;\n",
    "2. Enter your x500 ID (because I need to keep track of who submitted what). You should see a text display \"welcome!\" after you enter your ID;\n",
    "3. Upload the prediction file with the correct format as discussed above. After the file is uploaded, the performance metrics will be shown automatically, including the precision/recall/F-measure of each class and the average F-measure. The entire confusion matrix is not provided to prevent gaming behavior.\n",
    "\n",
    "If the submission system is not working at any point during this assignment, please contact me via email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading\n",
    "\n",
    "Your grade (out of 25 points) of this assignment is determined as follows:\n",
    "1. I rank everyone based on their highest performance. Say your rank is $A$;\n",
    "2. I rank everyone based on their second-highest performance. Say your rank is $B$;\n",
    "3. I rank everyone based on their third-highest performance. Say your rank is $C$;\n",
    "4. I compute a score (\"weighted average ranking\") $S = \\frac{1}{2}A + \\frac{1}{3}B + \\frac{1}{6}C$.\n",
    "5. The person(s) with the lowest $S$ gets 25 points, the person(s) with the second-lowest $S$ gets 24.5 points, so on and so forth.\n",
    "\n",
    "The design of this grading scheme **encourages consistent efforts that leads to steady performance improvement**, and demotes the relative importance of having one lucky high performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
